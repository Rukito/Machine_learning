{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Powtórka\n",
    "Na poprzednich wykładach zajmowaliśmy się:\n",
    "* sieciami liniowymi: łatwo można dla nich sformułować i udowodnić zbieżność gradientowej reguły uczenia. Niestety miały one ograniczenie do reprezentowania odwzorowań liniowych. \n",
    "* perceptornem Rosenblatta: łatwo można było wyprowadzić dla niego regułę uczenia, wnosił nową jakość- podział przestrzeni wejściowej na rozłączne obszary decyzyjne, składanie sieci wielowarstwowych wprowadza nową jakość (możliwość konstruowania dowolnych podziałów przestrzeni wejściowej ) ale:\n",
    "** dla jednej warstwy można rozwiązywać tylko problemy separowalne liniowo\n",
    "** dla większej ilości warstw brak jest reguły uczenia\n",
    "\n",
    "Problem z regułą uczenia perceptronu Rosenblatta bierze się z tego, że nie można do niej wykorzystać metod spadku gradientowego, ze względu na występującą w nim nieciągłość."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Formy nieliniowości\n",
    "Okazuje się, że w wielu przypadkach dobrze sprawdzają się następujące dwie funkcje sigmoidalne:\n",
    "## funkcja logistyczna:\n",
    "\n",
    "$\\qquad$$y = \\frac{1}{1+\\exp(-\\beta a)} $\n",
    "  * pochodna: $\\frac{dy}{da} = \\beta y (1-y)$\n",
    "  * zbiór wartości otwarty:$y \\in (0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## tangens hiperboliczny\n",
    "\n",
    "$\\qquad$$y = \\tanh(\\beta a) = \\frac{\\exp(\\beta a)-\\exp(-\\beta a)}{\\exp(\\beta a) + \\exp(-\\beta a)} $\n",
    "\n",
    "  * pochodna $\\qquad$$\\frac{d y }{d a} = \\beta (1+y)(1-y)$\n",
    "  * zbiór wartości $y \\in (-1,1)$\n",
    "We wszystkich powyższych wzorach $\\beta$ to parametr odpowiadający za stromość sigmoidy, zaś $a$ to aktywacja neuronu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## funkcja prostownicza: ReLu\n",
    "\n",
    "$\\qquad$ $y = \\max(0, a)$ gdzie $ a = W x +b$\n",
    "\n",
    "  * podstawową zaletą tej funkcji jest to, że ma stały niezerowy gradient (w zakresnie $a>0$) więc nie da się jej wysycić\n",
    "\n",
    "  * rzadka reprezentacja (dla $a\\le0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Uczenie reułą delta\n",
    "## Pojedynczy neuron: reguła delta\n",
    "Podobnie jak dla wszystkich omawianych dotychczas sieci celem uczenia neuronu nieliniowego jest taki dobór jego wag, aby zminimalizować błąd średnio-kwadratowy popełniany na ciągu uczącym. \n",
    "Niech ciąg uczący będzie:\n",
    "\n",
    "$\\qquad$$\\left\\{ \\left(X^{(j)}, z^{(j)}\\right)\\right\\}_{j = 1,\\dots,N} $\n",
    "\n",
    "Funkcja błędu to:\n",
    "\n",
    "$\\qquad$ $J(w) = \\frac{1}{2} \\sum_{j=1}^N\\left(z^{(j)}- y^{(j)} \\right)^2 = \\sum_{j=1}^N J^{(j)}(w)$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "$\\qquad$$y^{(j)} = f\\left(a^{(j)}\\right) = f \\left( \\sum_{i=0}^n w_i^{(j)} x_i^{(j)}\\right)$\n",
    "\n",
    "zaś\n",
    "\n",
    "$\\qquad$$J^{(j)}(w) = \\frac{1}{2} \\left( z^{(j)} -y^{(j)}\\right)^2 $\n",
    "\n",
    "podobnie jak w przypadku regresji liniowej chcemy zmieniać wag w kierunku przeciwnym do kierunku gradientu funkcji kosztu, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "tzn. po prezentacji $j$ przykładu $i$-ta waga zmienia się tak:\n",
    "\n",
    "$\\qquad$ $w_i^{(j+1)} - w_i^{(j)} = \\Delta w_i^{(j)} = -\\eta \\frac{\\partial J^{(j)} }{\\partial w_i} = \n",
    "-\\eta \\frac{\\partial J^{(j)} }{\\partial y^{(j)}} \\frac{\\partial y^{(j)}}{\\partial w_i} = - \\eta \\frac{\\partial J^{(j)} }{\\partial y^{(j)}} \\frac{\\partial y^{(j)}}{\\partial a} \\frac{\\partial a}{\\partial w_i}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "łatwo zauważyć, że:\n",
    "\n",
    "$\\qquad$ $\\frac{\\partial J^{(j)} }{\\partial y^{(j)}} = - \\left( z^{(j)} -y^{(j)}\\right) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "oraz, że:\n",
    "\n",
    "$\\qquad$ $ \\frac{\\partial a^{(j)}}{\\partial w_i} = x_i^{(j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "natomiast:\n",
    "\n",
    "$\\qquad$ $\\frac{\\partial y^{(j)}}{\\partial a^{(j)}} = \\frac{d f(a)}{da^{(j)}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Łącząc te wszystkie spostrzeżenia otrzymujemy:\n",
    "\n",
    "$\\qquad$ $ \\Delta w_i^{(j)} = \\eta \\frac{df(a)}{d a^{(j)}}\\left(z^{(j)} - y^{(j)}\\right)x_i^{(j)} = \\eta \\delta^{(j)}x_i^{(j)}$\n",
    "\n",
    "gdzie wprowadziliśmy:\n",
    "\n",
    "$\\qquad$ $\\delta^{(j)} = \\frac{df(a)}{da^{(j)}} \\left( z^{(j)}- y^{(j)}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uczenie nieliniowej sieci: Jak znaleźć błąd dla warstwy ukrytej?\n",
    "### Pomysł: \n",
    "błąd $\\delta_m^{(j)}$ występujący w ''j'' − tym kroku uczenia na neuronie ''m'' rzutujemy wstecz do wszystkich neuronów, które stanowią wejście dla neuronu ''m'' − tego.\n",
    "Rzutując, mnożymy błąd przez ten sam współczynnik wagowy, który w czasie propagacji ''w przód'' ważył wejście.\n",
    ";Dlaczego?\n",
    ";Uzasadnienie intuicyjne: Jeśli neuron warstwy ukrytej przyczynił się do powstania błędu na neuronie warstwy wyjściowej rzutując ''w przód'' przez dużą wagę, to trzeba mu zwrócić informację o błędzie proporcjonalnie do tej wagi.\n",
    "﻿﻿\n",
    "![](http://brain.fuw.edu.pl/edu/images/7/71/Rzutowanie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uzasadnienie formalne: \n",
    "\n",
    "Reguła ta wynika wprost z gradientowej metody minimalizacji funkcji błędu.\n",
    "Rozważmy sieć dwuwarstwową.\n",
    "![](http://brain.fuw.edu.pl/edu/images/b/bf/Backprop_oznaczenia.png)\n",
    "\n",
    "Dla wzorca $j$ − tego $k$ − ta jednostka ukryta otrzymuje pobudzenie:\n",
    "\n",
    "$\\qquad$ $a_k^{(j)} = \\sum_{i \\in U}w_i^{k{(j)}}x_i^{(j)}$\n",
    "\n",
    "gdzie: $ U $ - indeksy wejść warstwy ukrytej, $w_i^{k{(j)}}$ - $i$-ta waga $k$-tej jednostki w $j$-tym kroku uczenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Jednostka ta wytwarza sygnał wyjściowy:\n",
    "\n",
    "$\\qquad$ $V_k^{(j)} = f\\left( a_k ^{(j)}\\right) = f\\left(\\sum_{i \\in U} w_i^{k(j)} x_i^{(j)}\\right) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Jednostka wyjściowa, $n$ − ta, otrzymuje zatem sygnał:\n",
    "\n",
    "$\\qquad$$ a_n^{(j)} = \\sum_{i \\in Wyj} W_i^{n(j)}V_i^{(j)} = \\sum_{i \\in Wyj} \n",
    "W_i^{n(j)}f\\left(\\sum_{i \\in U} w_i^{k(j)}x_i^{(j)}\\right)\n",
    "$\n",
    "\n",
    "$\\qquad$(gdzie: $Wyj$ — indeksy wejść warstwy wyjściowej, _uwaga_: $a_n^{(j)} \\ne a_k^{(j)}$ dla $ n \\ne k $ !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "i wytwarza sygnał wyjściowy: \n",
    "\n",
    "$\\qquad$$y_n^{(j)} = f\\left(a_n^{(j)}\\right) = f\\left(\\sum_{i \\in Wyj} W_i^{n(j)} f\\left(\\sum_{i \\in U} w_i^{k(j)}x_i^{(j)}\\right)\\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Miara błędu wygląda tak:\n",
    "\n",
    "$\\qquad$$J(\\mathbf{w}) = \\frac{1}{2}\\sum_{n,j}\\left(z_n^{(j)} - y_n{(j)}\\right)^2 \n",
    "= \\frac{1}{2}\\sum_{n,j} \\left(z_n^{(j)} - f\\left( \\sum_{i \\in Wyj} W_i^{n(j)}f\\left(\\sum_{i \\in U}w_i^{k(j)}x_i^{(j)}\\right)\\right) \\right)^2\n",
    "$\n",
    "\n",
    "i jest ciągłą i różniczkowalną funkcją wszystkich wag, możemy więc ją minimalizować zmieniając wagi w kierunku przeciwnym do gradientu ($\\mathbf{w}$ to wszystkie wagi zarówno $w$ jak i $W$ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dla warstwy wyjściowej otrzymujemy:\n",
    "\n",
    "$\\qquad$$ \\Delta W_i^{n(j)} = -\\eta \\frac{\\partial J^{(j)}}{\\partial W_i^{n}} = \\eta \\left( z_n^{(j)} - y_n^{(j)}\\right) \\frac{df(a_n^{(j)})}{da} V_k^{(j)} = \\eta \\delta^{(j)} V_k^{(j)} $\n",
    "\n",
    "gdzie oznaczyliśmy: $\\delta_n^{(j)} = \\left( z_n^{(j)} - y_n^{(j)}\\right) \\frac{df(a_n^{(j)})}{da}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dla warstwy ukrytej otrzymujemy: \n",
    "![](http://brain.fuw.edu.pl/edu/images/6/6f/Backprop_2.png)\n",
    "\n",
    "$\\qquad$$\\Delta w_i^{k(j)} = -\\eta \\frac{\\partial J^{(j)}}{\\partial w_i^k} = -\\eta \\frac{\\partial J^{(j)}}{\\partial V_k }\\frac{\\partial V_k^{(j)}}{\\partial w_i^k} =$\n",
    "\n",
    "$\\qquad$$ = \\eta \\sum_n \\left(z_n^{(j)} - y_n^{(j)}\\right)\n",
    "\\frac{df(a_n^{(j)})}{d a_n}W_i^n \\frac{df(a_k^{(j)})}{da_k}  x_i^{(j)} =$\n",
    "\n",
    "$\\qquad$$=\\eta \\sum_n \\delta_n^{(j)}W_i^n \\frac{df(a_k^{(j)})}{da_k}x_i^{(j)} =$\n",
    "\n",
    "$\\qquad$$ =\\eta \\delta_k^{(j)} x_i^{(j)} $\n",
    "\n",
    "przy czym zdefiniowaliśmy: \n",
    "\n",
    "$\\qquad$$\\delta_k^{(j)} = \\frac{df(a_k^{(j)}) }{d a_k} \\sum_n W_i^n \\delta_n^{(j)}$\n",
    "\n",
    "Widać, że wzór na zmianę wag, czy to warstwy wejściowej, czy ukrytej ma tę samą postać, różni się jedynie definicją $ \\delta$. Dla warstw ukrytych błąd jest sumą ważoną (wagami połączeń \"do przodu\") błędów popełnionych w wyższej warstwie.\n",
    "\n",
    "Regułę tą można udowodnić dla dowolnej ilości warstw stosując odpowiednią ilość razy regułę łańcuchową."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problemy uczenia metodą wstecznej propagacji błędu \n",
    "* Minima lokalne funkcji kosztu. W odróżnieniu od funkcji kosztu dla problemu sieci liniowych w przypadku sieci nieliniowych funkcja kosztu ma zazwyczaj wiele lokalnych minimów. Algorytm wstecznej propagacji błędu jako algorytm spadku gradientowego nie jest odporny na ich występowanie. \n",
    "* Generalizacja: Uczenie z wykorzystaniem tylko jednego ciągu uczącego i reguły wstecznej propagacji błędu może prowadzić do problemów z generalizacją, czyli wynikami działania sieci na danych nie występujących w ciągu uczącym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Klasyczne przykłady zastosowań \n",
    "\n",
    "**XOR**: rozwiązanie metodą wstecznej propagacji dla jednostek sigmoidalnych — jednostki są sterowane w stronę wysycenia. Czas uczenia jest bardzo długi: setki epok prezentacji całego zbioru treningowego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Koder:** Dwuwarstwowa sieć o N wejściach, N wyjściach i M neuronach w warstwie ukrytej (M < N). Chcemy uzyskać autoasocjację czyli X(j) = Y (j). \n",
    "* Praktyczne zastosowanie — kompresja np. obrazów. \n",
    "* Teoretyczne — wyznaczanie możliwości sieci — problem łatwo można skalować i zmieniać jego trudność przez zmianę M/N.\n",
    "* automatyczne konstruowanie cech!\n",
    "![](http://brain.fuw.edu.pl/edu/images/8/86/Koder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**NETtalk** Klasyczna praca (Sejnowski i Rosenberg 1987,Complex Systems 1, 145–168): generacja ciągu fonemów z angielskiego tekstu pisanego.\n",
    "* Architektura: 7 × 29 wejść kodujących 7 kolejnych liter, 80 jednostek ukrytych, 26 jednostek wyjściowych kodujacych fonemy.\n",
    "* Zbiór uczący: 1024 słowa podawane w postaci par (litera,fonem)\n",
    "* Efekty: po 10 epokach zrozumiała wymowa, po 50 — 95% odtwarzania zbioru treningowego, 78% na ciągłym tekście źródłowym. Porównanie stanowi system algorytmiczny DEC-talk (jest lepszy)\n",
    "![](http://brain.fuw.edu.pl/edu/images/1/1d/NetTalk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Struktura drugorzędowa białka:** (Quian, Sejnowski (1988), Journal of Molecural Biology 202, 865–884). \n",
    "* Wejście — ruchome okno z 13 aminokwasów. \n",
    "* Na wyjściu odczytujemy prognozę struktury środkowej części okna jako spirali α, arkusza β lub innej struktury. \n",
    "* Efekt: na nowym zbiorze danych dokładność predykcji 62% (w porównaniu do konkurencyjnej metody 53%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Rozpoznawanie celów sonarowych:**(Gorman i Sejnowski (1988) Neural Network 1, 75–89) Problem: rozróżnianie sygnałów sonarowych odbitych albo od skał albo od metalowych cylindrów leżących na dnie zatoki.\n",
    "* Preprocessing: transformanta Fouriera \n",
    "* Architektura: 60 jednostek wejściowych i 2 wyjściowe, liczba jednostek ukrytych od 0 –24,\n",
    "* Na nowych danych (generalizacja ) dla 12 jednostek ukrytych ∼ 85%; poprawa jakości do ∼ 90% po staranniejszym wybraniu zbioru treningowego.\n",
    "![Wyniki różnych architektur dla zbioru uczącego](http://brain.fuw.edu.pl/edu/images/2/2b/Sonar_epoki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Kierowanie samochodem (Pomerlau, 1989):**\n",
    "* Sygnał wejściowy — obraz z kamery video 30 × 32 piksle umocowanej na dachu oraz obraz 8 × 32 piksle z dalmierza kodującego odległość w skali szarości, \n",
    "* warstwa ukryta 29 jednostek, wyjście 45 jednostek ułożonych w linię (środkowa jednostka kodowała jazdę na wprost, boczne — kąt skrętu odpowiednio w lewo lub w prawo).\n",
    "* Zbiór treningowy: 1200 symulowanych fragmentów drogi. Uczenie: około 40 powtórzeń każdego ze wzorców.\n",
    "* Efekt: sieć mogła prowadzić samochód z prędkością około 5 km/h po drodze przez zalesiony obszar wokół kampusu Carrengie-Mellon.\n",
    "Ograniczenie prędkości: moc obliczeniowa komputera — sieć symulowana była na komputerze Sun-3 (metody algorytmiczne dawały prędkość o połowę mniejszą)\n",
    " Przykład kierowania samochodem (czas 3:21-8:38): https://youtu.be/5u4G23_OohI?t=3m21s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Rozpoznawanie ręcznie pisanych kodów pocztowych(Le Cun 1989, Neural Computaion 1 541–551):**\n",
    "![Schemat sieci do rozpoznawania kodów pocztowych](http://brain.fuw.edu.pl/edu/images/1/14/Pismo.png)\n",
    "* Preprocessing: rozdzielenie kodów na po jedyncze\tcyfry,\twyskalowanie\tdo standardowych rozmiarów i skwantowanie na tablicę piksli 16 × 16.\n",
    "* W całej sieci było w sumie 1256 jednostek i 9700 niezależnych parametrów. \n",
    "* Nauka na zbiorze 7300 cyfr i test na 2000 cyfr.\n",
    "* Wynik: 1% błędów dla zbioru uczącego i 5% dla testowego. Po dopuszceniu odpowiedzi ”nie wiem” błąd na zbiorze testowym 1%, ale odrzucone było 12% cyfr. Dalszą poprawę generalizacji uzyskano po usunięciu niepotrzebnych wag (99% trafności przy 9% odrzutów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "progress": true,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif",
   "width": 1600
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
