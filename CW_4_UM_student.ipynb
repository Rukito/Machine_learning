{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja za pomocą algorytmu wektorów wspierających (SVM)\n",
    "## Materiały\n",
    "Na tych ćwiczeniach zapoznamy się z zastosowaniem SVM do klasyfikacji.\n",
    "Poniżej znajduje się fragment kodu dostarczający kilku funkcji,  z których dziś będziemy korzystać. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definicje funkcji pomocniczych, których nie musisz modyfikować"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rysujDaneGrup(X, y, marker, xlabel, ylabel,legend_list):\n",
    "    '''X - macierz wartości wejściowych zorganizowana tak, że kolejne przykłady są\n",
    "    w wierszach, kolumny to kolejne wynmiary  wejścia,\n",
    "    y - wektor określający przynależność do grupy, indeksy tego wektora odpowiadają wireszom macierzy X,\n",
    "    marker - zestaw markerów do oznaczania elementów grup, markerów powinno być tyle ile jest grup'''\n",
    "    p=[]\n",
    "    for i,g in enumerate(np.unique(y)):\n",
    "        g = int(g)\n",
    "        tmp =plt.plot(X[np.where(y==g),0],X[np.where(y==g),1],marker[i])\n",
    "        p.append(tmp[0])\n",
    "    plt.legend(p,legend_list)\n",
    "    # Dodajemy napisy\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "def rysujPodzial(model, X):\n",
    "    # wytworzymy siatkę punktów pokrywających obszar danych:\n",
    "    N = 100 # ilość punktów siatki w jednym wymiarze\n",
    "    os_x = np.linspace(X.min(),X.max(),N)\n",
    "    klasa = np.zeros((N,N))\n",
    "    for ix1, x1 in enumerate(os_x):\n",
    "        for ix2, x2 in enumerate(os_x):\n",
    "            XX = np.array([x1,x2]).reshape(1,2)\n",
    "            klasa[ix1,ix2] = svmPredict(model, XX) # dla każdego punktu siatki obliczamy jego klasę\n",
    "    \n",
    "    x1_grid,x2_grid = np.meshgrid(os_x,os_x)\n",
    "    plt.contourf(x1_grid, x2_grid, klasa.T,2)   \n",
    "            \n",
    "    \n",
    "def gaussianKernel(Xi,Xj,sigma=0.1):\n",
    "    z = np.dot((Xi-Xj).T,(Xi-Xj))\n",
    "    S = 2*sigma*sigma\n",
    "    Z= z/S\n",
    "    return np.exp(-Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja do trenowania modelu SVM. \n",
    "\n",
    "**Uwaga**: To jest wersja uproszczona algorytmu wzorowana na\n",
    "           https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf\n",
    "           \n",
    "w szczególności odwołuje się ona do numerów równań z tego artykułu.\n",
    "           \n",
    "Nie jest ani specjalnie elegancka ani szybka.\n",
    "\n",
    "Do praktycznych zastosowań zaleca się stosowanie zoptymalizowanych bibliotek:\n",
    "* LIBSVM   (http://www.csie.ntu.edu.tw/~cjlin/libsvm/)\n",
    "* SVMLight (http://svmlight.joachims.org/)\n",
    "* lub [sklearn](http://scikit-learn.org/stable/modules/svm.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmTrain(X, Y, C, kernelFunction, tol = 1e-3, max_passes = 5, sigma=0.1):\n",
    "    '''VMTRAIN Trenuje klasyfikator  SVM za pomocą uproszczonego algorytmu SMO.\n",
    "         X - macierz wejściowa  przykładów z ciągu uczącego wiersze - przyklady, kolumny - cechy\n",
    "         Y - wektor etykiet klas {-1,1}\n",
    "         C  - regularyzacja SVM\n",
    "         tol - tolerancja na odstępstwa od wrunków KTT\n",
    "         max_passes - ile iteracji bez zmian mnożników Lagrangaea wykonać zanim uznamy, że już nie ma co poprawiać\n",
    "        kernelFunction - funkcja jądra, zaimplementowane są:\n",
    "            - gaussianKernel\n",
    "            - linearKernel\n",
    "        sigma - standardowe odchylenie dla jądra gaussowskiego\n",
    "    \n",
    "    funkcja zwraca parametry doapsowanego modelu w słowniku model\n",
    "    '''\n",
    "\n",
    "    # Pobieramy rozmiary\n",
    "    m,n = X.shape #m - ilość przykładów, n - wymiar wejścia\n",
    "  \n",
    "\n",
    "    # Zmienne\n",
    "    alphas = np.zeros(m)\n",
    "    b = 0\n",
    "    E = np.zeros(m)\n",
    "    passes = 0\n",
    "    eta = 0\n",
    "    L = 0\n",
    "    H = 0\n",
    "\n",
    "    # Pre-compute the Kernel Matrix since our dataset is small\n",
    "    # (in practice, optimized SVM packages that handle large datasets\n",
    "    #  gracefully will _not_ do this)\n",
    "    # \n",
    "    # We have implemented optimized vectorized version of the Kernels here so\n",
    "    # that the svm training will run faster.\n",
    "    print('Obliczam macierz jądra')\n",
    "    if kernelFunction =='linearKernel':\n",
    "        # to jądro można policzyć od razu dla wszystkich przykładów\n",
    "        K = np.dot(X,X.T)\n",
    "    else:\n",
    "        # Jak nie możemy wymyśleć wektoryzacji obliczeń to\n",
    "        # obliczamy każdy element macierzy jądra osobno\n",
    "        K = np.zeros((m,m))\n",
    "        for i in range(m):\n",
    "            for j in range(i,m):\n",
    "                K[i,j] = gaussianKernel(X[i,:].T, X[j,:].T,sigma)\n",
    "                K[j,i] = K[i,j] #the matrix is symmetric\n",
    "       \n",
    "       \n",
    "    print('Trenuję ...')\n",
    "    dots = 12\n",
    "    while passes < max_passes:        \n",
    "        num_changed_alphas = 0\n",
    "        for i in range(m): #dla każdego przykładu z ciągu uczącego\n",
    "            # obliczamy błąd predykcji dla wektora i\n",
    "            E[i] = b + np.sum (alphas*Y*K[:,i]) - Y[i]\n",
    "            # jeśli jest co poprawiać:\n",
    "            if (( (Y[i]*E[i] < -tol) & (alphas[i] < C)) | ((Y[i]*E[i] > tol) & (alphas[i] > 0))):\n",
    "            \n",
    "                # In practice, there are many heuristics one can use to select\n",
    "                # the i and j. In this simplified code, we select them randomly.\n",
    "                j = int(np.floor(m * np.random.rand()))\n",
    "                while j == i:  # Make sure i \\neq j\n",
    "                    j = int(np.floor(m * np.random.rand()))\n",
    "            \n",
    "                # Obliczamy błąd predykcji dla wektora j.\n",
    "                E[j] = b + np.sum (alphas*Y*K[:,j]) - Y[j]\n",
    "\n",
    "                # Save old alphas\n",
    "                alpha_i_old = alphas[i]\n",
    "                alpha_j_old = alphas[j]\n",
    "            \n",
    "                # Oblicz przycięcia do pudełka [0,C] \n",
    "                if (Y[i] == Y[j]):\n",
    "                    L = np.max((0, alphas[j] + alphas[i] - C))\n",
    "                    H = np.min((C, alphas[j] + alphas[i]))\n",
    "                else:\n",
    "                    L = np.max((0, alphas[j] - alphas[i]))\n",
    "                    H = np.min((C, C + alphas[j] - alphas[i]))\n",
    "                if (L ==    H):\n",
    "                    # continue to next i. \n",
    "                    continue\n",
    "                # Compute eta by (15).\n",
    "                eta = 2 * K[i,j] - K[i,i] - K[j,j]\n",
    "                if (eta >= 0):\n",
    "                    # continue to next i. \n",
    "                    continue\n",
    "                # Compute and clip new value for alpha j using (16) and (17).\n",
    "                alphas[j] = alphas[j] - (Y[j] * (E[i] - E[j])) / eta\n",
    "            \n",
    "                # Clip \n",
    "                alphas[j] = np.min ((H, alphas[j]))\n",
    "                alphas[j] = np.max ((L, alphas[j]))\n",
    "            \n",
    "                #Check if change in alpha is significant\n",
    "                if (np.abs(alphas[j] - alpha_j_old) < tol):\n",
    "                    # continue to next i. \n",
    "                    # replace anyway\n",
    "                    alphas[j] = alpha_j_old\n",
    "                    continue\n",
    "            \n",
    "                # Determine value for alpha i using (16). \n",
    "                alphas[i] = alphas[i] + Y[i]*Y[j]*(alpha_j_old - alphas[j])\n",
    "            \n",
    "                # Compute b1 and b2 using (20) and (21) respectively. \n",
    "                b1 = b - E[i] - Y[i] * (alphas[i] - alpha_i_old) *  K[i,j] - Y[j] * (alphas[j] - alpha_j_old) *  K[i,j].T\n",
    "                b2 = b - E[j] - Y[i] * (alphas[i] - alpha_i_old) *  K[i,j] - Y[j] * (alphas[j] - alpha_j_old) *  K[j,j].T\n",
    "\n",
    "                # Compute b by (19). \n",
    "                if ( (0 < alphas[i]) & (alphas[i] < C)):\n",
    "                    b = b1\n",
    "                elif (0 < alphas[j]) & (alphas[j] < C):\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1+b2)/2\n",
    "                num_changed_alphas = num_changed_alphas + 1    \n",
    "        if (num_changed_alphas == 0):\n",
    "            passes = passes + 1\n",
    "        else:\n",
    "            passes = 0\n",
    "        print(num_changed_alphas)\n",
    "    print(' Gotowe! \\n\\n')\n",
    "\n",
    "    # Save the model\n",
    "    idx = alphas > 0    \n",
    "    model = {}\n",
    "    model['X'] = X[idx,:]\n",
    "    model['Y'] = Y[idx]\n",
    "    model['kernelFunction'] = kernelFunction\n",
    "    model['b'] = b\n",
    "    model['alphas']= alphas[idx]\n",
    "    model['w'] = (np.dot((alphas*Y).T, X)).T\n",
    "    model['sigma'] = sigma\n",
    "    print('ilość wektorów wspierających: ', len(model['alphas']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja do wykonywania predykcji modelu wyuczonego w oparciu o poprzednią funkcję trenującą:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmPredict(model,X):\n",
    "    '''model - model otrzymany z funkcji svmTrain\n",
    "     X - macierz m x n ,\n",
    "                       w której wierszach są przykłady do sklasyfikowania (m)\n",
    "                       każdy przykład ma wymiar n\n",
    "     funkcja zwraca wektor pred - i-ty element to predykcja dla i-tego przykładu\n",
    "    '''\n",
    "    \n",
    "    # pobieramy rozmiary:\n",
    "    m,n = X.shape\n",
    "    #print 'm,n',m,n\n",
    "    # przygotowujemy tablice:\n",
    "    pred = np.zeros(m) # predyktory\n",
    "    margines = np.zeros(m)     # wartości marginesów\n",
    "    if model['kernelFunction'] == 'linearKernel':\n",
    "        margines = np.dot(X , model['w']) + model['b']\n",
    "    elif model['kernelFunction'] =='gaussianKernel':\n",
    "        for i in range(m): #ta pętla iteruje po przykładach z macierzy X\n",
    "            for j in range(len(model['alphas'])): # ta pętlla iteruje po wektorach wspierających\n",
    "                margines[i] += model['alphas'][j]*model['Y'][j]* gaussianKernel(X[i,:],model['X'][j,:],model['sigma'])\n",
    "            margines[i] += model['b']\n",
    "    else:\n",
    "        print('niezaimplementowane jądro '+ model['kernelFunction'])\n",
    "    \n",
    "    pred[margines >= 0] =  1    \n",
    "    pred[margines <  0] = -1\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potrzebne będą nam też następujące zestawy danych:\n",
    "* [Dane1.txt](https://brain.fuw.edu.pl/edu/images/c/ce/Dane1.txt)\n",
    "* [Dane2.txt](https://brain.fuw.edu.pl/edu/images/3/3f/Dane2.txt)\n",
    "* [Dane3.txt](https://brain.fuw.edu.pl/edu/images/3/33/Dane3.txt).\n",
    "\n",
    "Proszę pobrać te pliki i zapisać je w bieżącym katalogu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 1: Dane separowalne liniowo\n",
    "Poniższy kod prezentuje zastosowanie SVM do problemu, który jest separowalny liniowo.\n",
    "Wykonując poniższy kod proszę zwrócić uwagę na punkt należący do klasy1 o współrzędnych (0.09, 4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = np.loadtxt('Dane1.txt') # dane zorganizowane są w trzech kolumnach\n",
    "N_przyk, N_wej = dane.shape \n",
    "X = dane[:,0:2] # pierwsze dwie kolumny to wejście\n",
    "y = dane[:,2] # trzecia kolumna to etykiety klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Narysujmy te dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rysujDaneGrup(X, y, marker=('or','xb'), xlabel='x0', ylabel='x1',legend_list=('klasa0','klasa1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trenujemy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = svmTrain(X, y, C=100, kernelFunction = 'linearKernel', tol = 1e-3, max_passes = 20,sigma = 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prezentujemy podział przestrzeni wejść reprezentowany przez model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rysujDaneGrup(X, y, marker=('or','xb'), xlabel='x0', ylabel='x1',legend_list=('klasa0','klasa1'))\n",
    "rysujPodzial(model,X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A jak jest dla innych wartości C?\n",
    "Jak pamiętamy z wykładu parametr C to współczynnik regularyzacji SVM, który karze za naruszanie marginesów. \n",
    "* Proszę wykonać  kod dla C o wartościach {1,2,5,10,20,30,60,120}  i zaobserwować wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2: jądro Gaussowskie\n",
    "W  programie proszę zmodyfikować wywołanie <tt>svmTrain</tt>:\n",
    "*  podmienić funkcję jądra na <tt>'gaussianKernel'</tt>.\n",
    "* ustawić C = 10\n",
    "* zmieniać sigma na wartości: {0.1, 0.2, 0.4, 0.8, 1, 2, 4, 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = svmTrain(X, y, C=..., kernelFunction = ... , tol = 1e-3, max_passes = 20,sigma = ...) \n",
    "rysujDaneGrup(X, y, marker=('or','xb'), xlabel='x0', ylabel='x1',legend_list=('klasa0','klasa1'))\n",
    "rysujPodzial(model,X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3: skomplikowany podział nieliniowy\n",
    "\n",
    "Przy pomocy kodu z ćwiczenia 2 proszę dobrać parametry C i sigma aby otrzymać sensownie wyglądający podział przestrzeni dla danych zawartych w pliku Dane2.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 4: automatyzacja dobierania parametrów C i sigma \n",
    "\n",
    "W wielu prawdziwych zastosowaniach chcielibyśmy aby nasz wybór parametrów był optymalny a jednocześnie możliwie  obiektywny. \n",
    "\n",
    "Powszechnie stosowaną metodą jest przeszukanie przestrzeni parametrów (C,sigma). Generuje się siatkę wartości (C,sigma) i dla każdego punktu siatki:\n",
    "\n",
    "* estymuje się model\n",
    "* ocenia się jakość generalizacji \n",
    "\n",
    "Do oceny jakości w każdym punkcie siatki można zastosować albo  zbiór monitorujący albo metody typu leave-one-out.\n",
    "\n",
    "**Uwaga**: podział przestrzeni często wykonuje się w skali logarytmicznej.\n",
    "\n",
    "Ćwiczenie wykonamy dla zbioru uczącego z pliku dane3.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dane = np.loadtxt('dane3.txt') # dane zorganizowane są w trzech kolumnach\n",
    "N_przyk, N_wej = dane.shape \n",
    "X = dane[:,0:2] # pierwsze dwie kolumny to wejście\n",
    "y = dane[:,2] # trzecia kolumna to etykiety klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musimy ten zbiór podzielić na dane do trenowania i dane do testowania np. w proporcji 3:1, Można to zrobić tak:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rozdzielamy dane na grupy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grupa0, = np.where(y==-1)\n",
    "grupa1, = np.where(y==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mieszamy kolejność indexów w każdej grupie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(grupa0)\n",
    "np.random.shuffle(grupa1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kopiujemy dane do zbioru uczącego (pierwsze 75% grupy0 i grupy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xu = X[np.concatenate((grupa0[0: int(0.75*len(grupa0))],grupa1[0:int(0.75*len(grupa0))]))]\n",
    "yu = y[np.concatenate((grupa0[0: int(0.75*len(grupa0))],grupa1[0:int(0.75*len(grupa0))]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kopiujemy dane do zbioru testowego (końcowe 25% grupy0 i grupy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = X[np.concatenate((grupa0[int(0.75*len(grupa0)):], grupa1[int(0.75*len(grupa0)):]))]\n",
    "yt = y[np.concatenate((grupa0[int(0.75*len(grupa0)):], grupa1[int(0.75*len(grupa0)):]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* narysujmy te dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rysujDaneGrup(Xu, yu, marker=('xr','xb'), xlabel='x0', ylabel='x1',legend_list=('klasa0','klasa1'))\n",
    "rysujDaneGrup(Xt, yt, marker=('or','ob'), xlabel='x0', ylabel='x1',legend_list=('klasa0_test','klasa1_test'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając taki podział danych możemy dopasować model SVM do części uczącej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = svmTrain(Xu, yu, C=10, kernelFunction = 'gaussianKernel', tol = 1e-3, max_passes = 20,sigma = 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A następnie ocenić jego jakość na części testowej (funkcja <tt>svmPredict</tt> dostarczana jest przez moduł svm_modul.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = np.sum(yt == svmPredict(model,Xt))/float(len(yt))\n",
    "print(TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proszę napisać kod, który\n",
    "* skanuje przestrzeń (C,sigma): C w zakresie od 0.1 do 100, sigma w zakresie od 0.1 do 10. Do wygenerowania zakresu ze skalą logarytmiczną można wykorzystać np. takie polecenie: <tt>zakresC = np.logspace(np.log2(0.1),np.log2(100),8, base=2)</tt>\n",
    "* znajduje najlepsze parametry\n",
    "* rysuje podział przestrzeni dla najlepszych parametrów."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
