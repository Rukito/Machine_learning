{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Powtórka\n",
    "* Jaką hipotezę wybraliśmy dla regresji logistycznej?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Co to jest funkcja wiarygodności?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*  Na czym polega \"Zasada największej wiarygodności\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jak pokazać, że dany rozkład należy do rodziny rozkładów wykładniczych?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\qquad$$ p(y;\\eta) = b(y) \\exp(\\eta^T T(y) - a(\\eta))$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jak znaleźć hipotezę dla danych modelowanych przez pewien znany rozkład w oparciu o GLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jak wygląda funkcją softmax i gdzie jej używamy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\qquad$$\\phi_i = \\frac{\\exp(\\eta_i)}{\\sum_{j=1}^k \\exp(\\eta_j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ocena klasyfikatorów binarnych\n",
    "\n",
    "* Klasyfikatory binarne to te, których zadaniem jest przypisanie danemu przykładowi jednej z dwóch możliwych klas. \n",
    "* Przykładem takiego klasyfikatora jest znana już nam regresja logistyczna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przykład klasyfikowania osób na zdrowe i chore na podstawie objawów. \n",
    "\n",
    "* Klasyfikator jako cechy przyjmuje na wejściu objawy (przedstawione w postaci numerycznej) i zwraca wynik klasyfikacji (testu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Zakładamy, że mamy dane zawierające zarówno objawy $O$ jak i faktyczny stan osoby $W$ dla pewnej grupy osób \n",
    " * $W$ może mieć dwie wartości: \n",
    "   * zdrowy, \n",
    "   * chory. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Mamy też pewien klasyfikator, który realizuje odwzorowanie:\n",
    "\n",
    "$\\qquad$ $H(O)  \\rightarrow K $\n",
    "\n",
    "* I tu podobnie, wynik klasyfikatora $K$ może przyjąć jedną z dwóch wartości: zdrowy lub chory. \n",
    "* W praktyce medycznej najczęściej mówimy, że pozytywny wynik testu wskazuje na chorobę."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Typy błędów\n",
    "Porównując wyniki $W$ i $K$ możemy mieć cztery sytuacje, \n",
    "![](ROC_table.png)\n",
    "\n",
    "Anglojęzyczna nomenklatura często stosowana do opisu tych możliwości to:\n",
    "* TP: true positive,  hit\n",
    "* TN: true negative,  correct rejection\n",
    "* FP: false positive, false alarm, Type I error\n",
    "* FN: false negative, with miss, Type II error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Miary\n",
    "* Jeśli mamy zbiór uczący o pewnej liczebności to dla każdego z elementów zbioru uczącego zachodzi jedna z powyżej opisanych możliwości. \n",
    "* Dla całego zbioru uczącego mamy konkretne liczby przypadków każdego typu. \n",
    "* Zliczenia tych przypadków są podstawą do stworzenia pewnych miar pozwalających na ocenę klasyfikatora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Czułość i specyficzność \n",
    "* czułość: Prawdopodobieństwo, że klasyfikacja będzie poprawna pod warunkiem, że przypadek jest pozytywny (ang. True Positive Rate). \n",
    "\n",
    "$\\qquad$ $TPR = \\frac{TP}{ P} = \\frac{TP} { TP+FN}$\n",
    " > Prawdopodobieństwo, że test wykonany dla osoby chorej wykaże, że jest ona chora.\n",
    "\n",
    "* specyficzność: Prawdopodobieństwo, że klasyfikacja będzie poprawna, pod warunkiem, że przypadek jest negatywny (ang. False Positive Rate). \n",
    "$\\qquad$ $SPC = \\frac{TN}{  N} = \\frac{TN} { FP + TN} = 1 - FPR $\n",
    " > Prawdopodobieństwo, że dla osoby zdrowej test nie wykryje choroby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Fałszywe alarmy### \n",
    "* częstość fałszywych alarmów:  (False Positive Rate)\n",
    " > Jak dużej frakcji osób zdrowych test wyjdzie pozytywnie?\n",
    "$\\qquad$ $FPR = \\frac{FP}{ N} = \\frac{FP}{ FP + TN} = 1-SPC$\n",
    "* częstość fałszywych odkryć: (False Discovery Rate (FDR)): \n",
    " > Jak duża frakcja spośród pozytywnych wyników testu jest fałszywa?\n",
    "$\\qquad$ $FDR = \\frac{FP}{P'}=\\frac{FP}{ FP + TP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Własności predykcyjne: Precyzja\n",
    "* precyzja pozytywna: (positive predictive value (PPV), precision). Odpowiada na pytanie: \n",
    " > Jeśli wynik testu jest pozytywny, jakie jest prawdopodobieństwo, że osoba badana jest chora? \n",
    "$\\qquad$ $PPV = \\frac{TP}{P'}=\\frac{TP}{ TP + FP}$\n",
    "\n",
    "* precyzja negatywna: (negative predictive value (NPV).) Odpowiada na pytanie: \n",
    " > Jeśli wynik testu jest negatywny, jakie jest prawdopodobieństwo, że osoba badana jest zdrowa?\n",
    "$\\qquad$ $NPV =\\frac{TN }{N'} =\\frac{TN }{ TN + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "####  Efekt częstości występowania \n",
    "Częstość występowania ma znaczący wpływ na opisane powyżej wartości predykcyjne. \n",
    "* Przypuśćmy, że mamy test na pewną chorobę i charakteryzuje się on 99% czułością i 99% specyficznością. \n",
    "* Załóżmy, że testowanych jest 2000 osób  i częstość występowania choroby (w próbie) wynosi 50%, \n",
    "  * to znaczy 1.000 z nich są chore a 1000 z nich są zdrowe. \n",
    "* W takiej sytuacji spodziewamy się  około 990 wyników TP i  990 TN oraz około 10 wyników FP i 10 FN. \n",
    "* Dodatnie (PPV = 99%) i ujemne (NPV = 99%) wartości predykcyjne są duże, więc możemy mieć wysokie zaufanie do wyniku. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jednakże, w przypadku gdy częstość występowania choroby będzie wynosiła  tylko 5%, \n",
    "  * czyli z 2000 osób tylko 100 jest chorych, \n",
    "* Prawdopodobnym rezultatem jest TP = 99, FN = 1, TN = 1881 i FP = 19. \n",
    "* Spośród 19 + 99 osób pozytywnych, tylko 99 naprawdę są chorzy\n",
    "  * to znaczy, że biorąc pod uwagę, że wynik badania pacjenta jest dodatni, jest tylko PPV =0.84 szans, że jest on naprawdę chory. \n",
    "  * Z drugiej strony biorąc pod uwagę ujemny wynik testu pacjenta, jest tylko 1 szansa na 1882 (NPV= 0,999 ), że pacjent cierpi na chorobę, mimo ujemnego wynik testu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Liczebność populacji: 2000\n",
      "częstość występowania choroby: 0.99\n",
      "czułość: 0.99 \t specyficzność: 0.99\n",
      "_________________________________________________________________\n",
      "oczekiwana liczba osób \t\t| chorych: 1980\t| zdrowych   20\n",
      "prawidłowo zdiagnozowanych \t| chorych: 1960\t| zdrowych   20\n",
      "błędnie zakwalifikowanych jako\t| chorych:    0\t| zdrowych   20\n",
      "_________________________________________________________________\n",
      "precyzja pozytywna: 1.000 \t| precyzja negatywna 0.500\n"
     ]
    }
   ],
   "source": [
    "N_pop = 2000\n",
    "TPR = 0.99 # czułość\n",
    "SPC = 0.99 # specyficzność\n",
    "f_wyst = 0.99 # częstość występowania\n",
    "P = N_pop * f_wyst # oczekiwana liczba osób chorych\n",
    "N = N_pop * (1-f_wyst) # oczekiwana liczba osób zdrowych\n",
    "TP = TPR * P # spodziewana liczba przypadków TP\n",
    "TN = SPC * N # spodziewana liczba przypadków TN\n",
    "FP = N - TN\n",
    "FN = P - TP\n",
    "PPV = TP/(TP + FP)\n",
    "NPV = TN/(TN + FN)\n",
    "print(\"_________________________________________________________________\")\n",
    "print(\"Liczebność populacji: %d\"%(N_pop))\n",
    "print(\"częstość występowania choroby: %.2f\"%(f_wyst))\n",
    "print(\"czułość: %.2f \\t specyficzność: %.2f\"%(TPR,SPC))\n",
    "print(\"_________________________________________________________________\")\n",
    "print(\"oczekiwana liczba osób \\t\\t| chorych: %4.0f\\t| zdrowych %4.0f\"%(P,N) )\n",
    "print(\"prawidłowo zdiagnozowanych \\t| chorych: %4.0f\\t| zdrowych %4.0f\"%(TP,TN) )\n",
    "print(\"błędnie zakwalifikowanych jako\\t| chorych: %4.0f\\t| zdrowych %4.0f\"%(FP,FN))\n",
    "print(\"_________________________________________________________________\")\n",
    "print(\"precyzja pozytywna: %3.3f \\t| precyzja negatywna %.3f\"%(PPV,NPV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Miary zbalansowane\n",
    "Powyżej rozważane miary były sparowane, tzn. trzeba obie jednocześnie brać pod uwagę przy ocenie testu/klasyfikatora.  Poniżej są definicje popularnych miar sprowadzonych do jednej liczby, która w pewnym stopniu opisuje całościowo wyniki.\n",
    "\n",
    "* dokładność ( accuracy (ACC)): Prawdopodobieństwo prawidłowej klasyfikacji.\n",
    "\n",
    "$\\qquad$ $ACC = \\frac{TP + TN}{P + N}$\n",
    "\n",
    "* F1-score: średnia harmoniczna z precyzji i czułości:\n",
    "\n",
    "$\\qquad$ $F_1= 2 \\frac{PPV  \\cdot TPR}{PPV+TPR}= \\frac{2TP}{ 2TP+FP+FN}$\n",
    "Miara ta daje ocenę balansu między czułością a precyzją. Miara ta nie uwzględnia wyników prawdziwie negatywnych.\n",
    "\n",
    "* $F_\\beta$ jest uogólnieniem powyższej miary, które pozwala regulować za pomocą parametru $\\beta$ wagę jaką przykładamy do PPV:\n",
    "\n",
    "$\\qquad$ $F_\\beta = (1+ \\beta^2) \\frac{PPV \\cdot TPR}{PPV \\beta^2 +TPR} $\n",
    "\n",
    "* współczynnik korelacji Matthews ( Matthews correlation coefficient):\n",
    "\n",
    "$\\qquad$ $\n",
    "\\text{MCC} = \\frac{ TP \\cdot TN - FP \\cdot FN } {\\sqrt{ (TP + FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }\n",
    "$\n",
    "\n",
    "  * Ten współczynnik uwzględnia wyniki zarówno prawdziwie jaki i fałszywie pozytywne i negatywne i jest na ogół uważany jako zrównoważona miara, która może być stosowana nawet wtedy, gdy klasy są bardzo różnej liczebności. \n",
    "  * MCC jest w istocie współczynnikiem korelacji pomiędzy obserwowanymi i przewidywanymi klasyfikacjami binarnymi; zwraca wartość od -1 do +1. \n",
    "    * Współczynnik +1 odpowiada idealnej klasyfikacji, \n",
    "    * 0 nie lepiej niż losowe przypisanie wyniku i \n",
    "    * -1 oznacza całkowitą niezgodę między klasyfikacją  i stanem faktycznym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Klasyfikator z progiem  \n",
    "Powyżej rozważaliśmy test/klasyfikator dający wynik binarny. Łatwo jest sobie wyobrazić, że klasyfikator ma ciągłe wyjście, które po porównaniu z pewną wartością progową daje dopiero ostateczny wynik. W takiej sytuacji warto mieć metodę pozwalającą na świadomy wybór optymalnego progu i na ocenę klasyfikatora, abstrahując od konkretnej wartości progu. Takich możliwości dostarcza analiza ROC.\n",
    "\n",
    "![](ROC_rozklady.png)\n",
    "\n",
    "Prawdopodobieństwa podejmowania każdego rodzaju decyzji będą się zmieniały wraz z przesuwaniem progu podejmowania decyzji, czyli wartości hipotezy przy której zaliczamy przypadek do klasy 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Krzywe charakterystyki roboczej odbiorcy (ROC)\n",
    "**Krzywa ROC**: każdy punkt na tej krzywej otrzymywany jest dla ustalonej wartości progu i ma współrzędne (1−specyficzność, czułość).\n",
    "\n",
    "Demo ilustrujące powstawanie krzywej ROC: HowReceiverOperatingCharacteristicCurvesWork.nb\n",
    "\n",
    "http://arogozhnikov.github.io/2015/10/05/roc-curve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Krzywa ROC przydaje się do porównywania różnych klasyfikatorów oraz do wyboru punktu pracy (progu)\n",
    "\n",
    "AUC: Pole powierzchni pod krzywą ROC ma interpretację probabilistyczną: \n",
    " > jest to prawdopodobieństwo tego, że klasyfikator przydzieli wyższą rangę dla losowo wybranego przypadku pozytywnego niż negatywnego (zakładając, że wynik pozytywny ma wyższą rangę niż negatywny) \n",
    " \n",
    "W tym sensie jest ono blisko związane ze statystyką Wilcoxona [http://pubs.rsna.org/doi/abs/10.1148/radiology.143.1.7063747]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Walidacja krzyżowa (Cross-validation)\n",
    "## Generalizacja: O co tu chodzi?  \n",
    "<img src=\"Generalizacja.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "Na rysunku powyżej przedstawiona jest schematycznie koncepcja generalizacji. \n",
    "* Wyobraźmy sobie, że jest pewna przestrzeń P, która zawiera pary, np. liczb {((a,b), c)}. \n",
    "* W tym przykładzie jest to przestrzeń wszystkich odwzorowań $\\mathcal{R}^2 \\rightarrow \\mathcal{R}$. \n",
    "* Niektóre z tych par reprezentują pewną konkretną relację R: np. są to pary spełniające warunek $c=\\sqrt{a^2 +b^2}$. \n",
    "* Wyobraźmy sobie dalej, że mamy dane dwa skończone zestawy par, które tą relację spełniają, ale oczywiście nie są w stanie obejmować wszystkich możliwych par. \n",
    "* Jeden z nich oznaczymy U, a drugi T. Załóżmy, że mamy dwie wersje klasyfikatora, które uczymy na zbiorze U (mogą się one różnić architekturą, albo punktem startu procedury uczącej, albo ilością iteracji algorytmu uczącego itp.).\n",
    "* Po procesie uczenia klasyfikatory te mają mały i porównywalny błąd na zbiorze U, ale jedna z nich nauczyła się relacji wskazanej na rys. jako g1 a druga relacji g2. \n",
    "* Na podstawie rezultatów odtwarzania przykładów ze zbioru testowego mówimy, że klasyfikator drugi ma lepszą generalizację niż klasyfikator pierwszy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Porównywanie klasyfikatorów  na podstawie błędów generalizacji.\n",
    "Najlepiej byłoby mieć możliwie mały błąd generalizacji — jak go oszacować?\n",
    "Można zastosować następujące techniki:\n",
    "* wiele zbiorów testowych:  trzeba mieć dużo danych, żeby wystarczyło na rozsądny zbiór treningowy i kilka testowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* kros-walidacja: najprostsza wersja (leave-one-out):\n",
    "  * wybierz przypadek do odrzucenia\n",
    "  * trenuj klasyfikator na wszystkich przypadkach oprócz tego jednego — na tym jednym oblicz błąd generalizacji\n",
    "  * powtarzaj to dla każdego przypadku <br>Zaleta — można efektywnie użyć całego zbioru danych do uczenia i testowania, <br>Cena — wielokrotne uczenie sieci\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Bootstrapowanie — wielokrotnie losuje się z powtórzeniami z pełnego zbioru dwie próby:\n",
    "  * do nauki klasyfikatora\n",
    "  * do testowania."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "progress": true,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif",
   "width": 1600
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
